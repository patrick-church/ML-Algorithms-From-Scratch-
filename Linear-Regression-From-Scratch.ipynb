{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.90</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.9240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.77</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.5523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.00</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.4620</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex    bmi  children smoker     region     charges\n",
       "0   19  female  27.90         0    yes  southwest  16884.9240\n",
       "1   18    male  33.77         1     no  southeast   1725.5523\n",
       "2   28    male  33.00         3     no  southeast   4449.4620"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"Data/insurance.csv\")\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_raw = data.drop(columns = [\"charges\"])\n",
    "y = np.asarray(data[\"charges\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = ColumnTransformer([\n",
    "    (\"num\", Pipeline([\n",
    "        (\"imp\", SimpleImputer(strategy = \"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ]), X_raw.select_dtypes(include = \"number\").columns),\n",
    "    (\"cat\", Pipeline([\n",
    "        (\"imp\", SimpleImputer(strategy = \"most_frequent\")),\n",
    "        (\"ohe\", OneHotEncoder(handle_unknown = \"ignore\", sparse_output= False))\n",
    "    ]), X_raw.select_dtypes(exclude = \"number\").columns)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pre.fit_transform(X_raw)\n",
    "\n",
    "if type(X) != np.ndarray:\n",
    "    X = X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression2:\n",
    "    def __init__(self, iterations : int = 100, learning_rate : float = 0.001, gradient_descent : str = 'batch'):\n",
    "        self.iterations = iterations\n",
    "        self.learning_rate = learning_rate\n",
    "        self.gradient_descent = gradient_descent\n",
    "        self.betas = None\n",
    "        self.intercept = 0.0\n",
    "        self.train_loss = []\n",
    "        self.val_score = []\n",
    "        self.all_train_loss = []\n",
    "\n",
    "    def initialize(self, n_features):\n",
    "        self.betas = np.zeros(n_features, dtype = float)\n",
    "        self.intercept = 0\n",
    "\n",
    "    def compute_gradients_update_weights(self, x : np.array, y : np.array):\n",
    "        x = np.asarray(x, dtype = float)\n",
    "        y = np.asarray(y, dtype = float)\n",
    "\n",
    "        if self.gradient_descent == 'batch':\n",
    "            y_pred = x @ self.betas + self.intercept\n",
    "\n",
    "            der_loss_wrt_preds = 2 * (y_pred - y)\n",
    "            #der_preds_wrt_weights = x\n",
    "            betas_gradients = (x.T @ der_loss_wrt_preds) / x.shape[0]\n",
    "            intercept_gradient = np.mean(der_loss_wrt_preds)\n",
    "\n",
    "            self.betas -= self.learning_rate * betas_gradients\n",
    "            self.intercept -= self.learning_rate * intercept_gradient\n",
    "\n",
    "        if self.gradient_descent == 'stochastic':\n",
    "            for row in range(x.shape[0]):\n",
    "                y_pred = x[row] @ self.betas + self.intercept \n",
    "\n",
    "                der_loss_wrt_pred = 2 * (y_pred - y[row])\n",
    "                #der_preds_wrt_weights = x[row]\n",
    "\n",
    "                betas_gradients = der_loss_wrt_pred * x[row]\n",
    "                intercept_gradient = der_loss_wrt_pred\n",
    "\n",
    "                self.betas -= self.learning_rate * betas_gradients\n",
    "                self.intercept -= self.learning_rate * intercept_gradient\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def predict(self, x : np.array):\n",
    "        x = np.asarray(x, dtype = float)\n",
    "        y_pred = x @ self.betas + self.intercept\n",
    "\n",
    "        return y_pred\n",
    "    \n",
    "    def track_loss(self, x : np.array, y : np.array):\n",
    "        x = np.asarray(x, dtype = float)\n",
    "        y = np.asarray(y, dtype = float)\n",
    "\n",
    "        y_pred = self.predict(x)\n",
    "        loss = np.sum((y - y_pred)**2) / x.shape[0]\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    \n",
    "    def fit(self, x_train : np.array, y_train : np.array):\n",
    "        x_train = np.asarray(x_train, dtype = float)\n",
    "        y_train = np.asarray(y_train, dtype = float)\n",
    "\n",
    "        if x_train.shape[0] != len(y_train):\n",
    "            raise ValueError(\"x_train and y_train must have the same amount of rows\")\n",
    "\n",
    "        self.initialize(x_train.shape[1])\n",
    "\n",
    "        self.train_loss = []\n",
    "\n",
    "        for iteration in range(self.iterations):\n",
    "            self.compute_gradients_update_weights(x_train, y_train)\n",
    "            trainloss = self.track_loss(x_train, y_train)\n",
    "            self.train_loss.append(trainloss)\n",
    "\n",
    "        return self.train_loss\n",
    "    \n",
    "    def cross_validate(self, x, y):\n",
    "        x = np.asarray(x, dtype = float)\n",
    "        y = np.asarray(y, dtype = float)\n",
    "\n",
    "        cv = KFold(n_splits = 5, shuffle = True, random_state = 42)\n",
    "\n",
    "        for train_idx, val_idx in cv.split(x, y):\n",
    "            x_train = X[train_idx]\n",
    "            y_train = y[train_idx]\n",
    "            x_val = X[val_idx]\n",
    "            y_val = y[val_idx]\n",
    "\n",
    "            model = LinearRegression2(\n",
    "                learning_rate = self.learning_rate,\n",
    "                iterations = self.iterations,\n",
    "                gradient_descent = self.gradient_descent\n",
    "            )\n",
    "\n",
    "            train_loss = model.fit(x_train, y_train)\n",
    "            self.all_train_loss.append(train_loss)\n",
    "            y_val_pred = model.predict(x_val)\n",
    "\n",
    "            val_eval = r2_score(y_val, y_val_pred)\n",
    "\n",
    "            self.val_score.append(val_eval)\n",
    "\n",
    "        return self.val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = LinearRegression2(learning_rate = 0.01, iterations = 1000, gradient_descent = \"batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 avg loss: 49084284.65365079, r2 score: 0.78\n",
      "Fold 2 avg loss: 48160136.83907313, r2 score: 0.74\n",
      "Fold 3 avg loss: 49144419.08123899, r2 score: 0.8\n",
      "Fold 4 avg loss: 47906243.80218184, r2 score: 0.63\n",
      "Fold 5 avg loss: 47684770.815754, r2 score: 0.75\n"
     ]
    }
   ],
   "source": [
    "n_splits = 5\n",
    "for fold in range(1, n_splits + 1):\n",
    "    fold_avg_loss = np.mean(instance.all_train_loss[fold - 1])\n",
    "    val_score = np.round(instance.cross_validate(X, y), 2)\n",
    "    print(f\"Fold {fold} avg loss: {fold_avg_loss}, r2 score: {val_score[fold - 1]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
